{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with the rest of the labels\n",
    "\n",
    "In the main notebook we have worked with the exciting label; explaining carefully the steps we have followed in order to find the best solution (with the PCAs features). \n",
    "\n",
    "In this way this notebook have the intention to find a model with the PCA features for every one of the given labels based on the previous steps which have been done in the main notebook. (If you are looking to explanations or reasons we refers to the other notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "import joblib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = './data/' #The data is in the .gitignore in order to not upload it to the GitHub repository\n",
    "VIS_FOLDER = './visualizations/' #Folder where save the visualizations\n",
    "MODELS_FOLDER = './sklearn_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['pleasant', 'interesting', 'exciting', 'calming', 'complex', 'bright', 'view', 'spacious']\n",
    "LIMIT = 7  ## Change this variable for working with the percentage of people how felt more than LIMIT-excited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\npyarrow or fastparquet is required for parquet support",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-abf24df1f862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_FOLDER\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"original_data.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/io/parquet.pyc\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \"\"\"\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/io/parquet.pyc\u001b[0m in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         raise ImportError(\"Unable to find a usable engine; \"\n\u001b[0m\u001b[1;32m     30\u001b[0m                           \u001b[0;34m\"tried using: 'pyarrow', 'fastparquet'.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                           \u001b[0;34m\"pyarrow or fastparquet is required for parquet \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\npyarrow or fastparquet is required for parquet support"
     ]
    }
   ],
   "source": [
    "df_ml = pd.read_parquet(DATA_FOLDER + \"original_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to use the PCA features, so we can remove the others from the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_ml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1c1b7282c792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Pattern'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Context'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SkyType'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pleasant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'interesting'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exciting'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'calming'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'complex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bright'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'view'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'spacious'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_ml' is not defined"
     ]
    }
   ],
   "source": [
    "df_ml = df_ml[['Country', 'Pattern', 'Context', 'SkyType','pleasant', 'interesting', 'exciting', 'calming', 'complex', 'bright', 'view', 'spacious']]\n",
    "df_ml.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_ml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-66eb91f16340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#fdata -> first data without preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Pattern'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Context'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SkyType'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_ml' is not defined"
     ]
    }
   ],
   "source": [
    "fdata = df_ml.iloc[:,0:4] #fdata -> first data without preprocessing\n",
    "fdata.drop_duplicates(inplace = True)\n",
    "fdata.set_index(['Country', 'Pattern', 'Context', 'SkyType'], inplace = True)\n",
    "\n",
    "\n",
    "computing_percentages_total_df = df_ml[['Country', 'Pattern', 'Context', 'SkyType']].copy()\n",
    "computing_percentages_total_df[\"Total_people\"] = 0\n",
    "computing_percentages_total_df = computing_percentages_total_df.groupby(['Country', 'Pattern', 'Context', 'SkyType']).count()\n",
    "\n",
    "perc_list_names = []\n",
    "for label in label_list:\n",
    "    percentage_name = \"Percentage_\" + label\n",
    "    perc_list_names = perc_list_names + [percentage_name]\n",
    "    \n",
    "    df_ml_over_limit = df_ml[df_ml[label] >= LIMIT]\n",
    "    computing_percentages_df2 = df_ml_over_limit[['Country', 'Pattern', 'Context', 'SkyType']].copy()\n",
    "    computing_percentages_df2[\"People_who_felt_label_feeling\"] = 0\n",
    "    computing_percentages_df2 = computing_percentages_df2.groupby(['Country', 'Pattern', 'Context', 'SkyType']).count()\n",
    "    \n",
    "    computing_percentages_joined = pd.DataFrame.join(computing_percentages_total_df, computing_percentages_df2).fillna(value=0)\n",
    "    \n",
    "    fdata = fdata.join(computing_percentages_joined)\n",
    "    fdata[percentage_name] = fdata[\"People_who_felt_label_feeling\"] / fdata[\"Total_people\"]\n",
    "    fdata = fdata.drop(columns = [\"People_who_felt_label_feeling\", \"Total_people\"])\n",
    "    \n",
    "#fdata.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8e090ea175ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fdata' is not defined"
     ]
    }
   ],
   "source": [
    "fdata.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a data frame with the compressed image pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\npyarrow or fastparquet is required for parquet support",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-40df632346f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpixels_excited_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_FOLDER\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"pixels_compressed.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpixels_excited_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpixels_excited_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Pattern'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Context'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SkyType'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/io/parquet.pyc\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \"\"\"\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/io/parquet.pyc\u001b[0m in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         raise ImportError(\"Unable to find a usable engine; \"\n\u001b[0m\u001b[1;32m     30\u001b[0m                           \u001b[0;34m\"tried using: 'pyarrow', 'fastparquet'.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                           \u001b[0;34m\"pyarrow or fastparquet is required for parquet \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\npyarrow or fastparquet is required for parquet support"
     ]
    }
   ],
   "source": [
    "pixels_excited_df = pd.read_parquet(DATA_FOLDER + \"pixels_compressed.parquet\")\n",
    "pixels_excited_df.reset_index(inplace = True)\n",
    "pixels_excited_df.set_index(['Country', 'Pattern', 'Context', 'SkyType'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_for_PCA = pixels_excited_df.drop(columns = \"Percentage_excited_people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_for_PCA.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, having a data frame with the percentages and another data frame with the compressed images pixels we join them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame.join(pixels_for_PCA, fdata)\n",
    "pca_df.reset_index(inplace = True)\n",
    "pca_df.set_index(['Pattern', 'Context', 'SkyType'], inplace = True)\n",
    "pca_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and ridge regression for every label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_labels_greece = pca_df[pca_df[\"Country\"]==\"Greece\"]\n",
    "\n",
    "#The pixels are the same for Greece and for Switzerland, since the images are the same ones\n",
    "x_matrix_temp = [pixels_array.tolist() for pixels_array in pixels_labels_greece[\"img_array\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preparing Matrices\n",
    "X_greece = x_matrix_temp\n",
    "y_greece = pixels_labels_greece[perc_list_names]\n",
    "\n",
    "#X_digits_switz = x_matrix_temp_switz\n",
    "#y_digits_switz = pixels_switz[labels].values\n",
    "\n",
    "## Standardize\n",
    "X_greece = preprocessing.scale(X_greece)\n",
    "\n",
    "\n",
    "## Pol expansion (in our case add a constant (bias)) for all data\n",
    "#pol = PolynomialFeatures(1, True, True)\n",
    "#phX_greece = pol.fit_transform(X_greece, y_digits_greece)\n",
    "#phx_greece = X_greece # for no pol\n",
    "\n",
    "## Splitting of the data\n",
    "X_train_greece, X_test_greece, y_train_greece, y_test_greece = train_test_split(X_greece, y_greece, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline to search for the best combination of PCA truncation\n",
    "# and classifier regularization.\n",
    "pca = PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('rig_reg', Ridge(solver=\"lsqr\"))])\n",
    "\n",
    "#Parameters for the PCA and the Ridge during the GridSearch:\n",
    "PCA_n_comp = np.arange(8, 28)  #(1,28) # must be between 0 and min(n_samples, n_features)=n_samples=len(X_train)=28\n",
    "lambdas = np.logspace(2, 5, 10) + [13895]  #13895 lambda which gave the best results with the 'exciting' label\n",
    "\n",
    "## Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {'pca__n_components': PCA_n_comp, 'rig_reg__alpha': lambdas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_greece = []\n",
    "for i in range(len(label_list)):\n",
    "    #Grid search will take by default the estimator's default scorer, i.e. the least squares from ridge regression estimator\n",
    "    search_greece = search_greece + [GridSearchCV(pipe, param_grid, iid=False, cv=5, return_train_score=True, scoring = 'neg_mean_absolute_error')] \n",
    "    \n",
    "    ## Modeling\n",
    "    print(len(X_train_greece))\n",
    "    print(len(X_train_greece[0]))\n",
    "    print(len(y_train_greece[perc_list_names[i]].values))\n",
    "    search_greece[i].fit(X_train_greece, y_train_greece[perc_list_names[i]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(label_list)):\n",
    "    print(\"LABEL: %s\" ,label_list[i])\n",
    "    ## Modeling\n",
    "    print(\"Best parameters set found on development set:\\n%s \\n\", search_greece[i].best_params_)\n",
    "    print(\"With best error:\\n%s \\n\", sum(abs(search_greece[i].predict(X_test_greece)-y_test_greece[perc_list_names[i]]))/len(X_test_greece[:,0]))\n",
    "    model_name = \"grid_pca_ridge_label\" + label_list[i]\n",
    "    joblib.dump(search_greece[i], MODELS_FOLDER + model_name + '.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
